{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(encoded_data, original_data, model_name, model_type):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "        encoded_data: would be only text embeddings from encoders such as USE\n",
    "    \n",
    "        original_data: originally scrapped data that includes cat1 & cat2\n",
    "    \n",
    "        model_name: string, name of the model that you are going to save as\n",
    "    \n",
    "        model_type: type of model you are building in the hierarchy, supported \n",
    "        options are X (directly predicting cat2), X1 (predicting cat1), \n",
    "        X2X (predicting cat2 after cat1s are predicted)\n",
    "    \n",
    "    Output:\n",
    "        X2X saves as many models as there is cat1 in the dataset\n",
    "    \"\"\"\n",
    "    if model_type == \"X\":\n",
    "        cat1 = original_data['cat1'].reset_index(drop=True)\n",
    "        cat2 = original_data['cat2'].reset_index(drop=True)\n",
    "        df1 = pd.concat([encoded_data,cat1,cat2],axis=1,ignore_index=True)\n",
    "        df1.rename(columns={ df1.columns[-2]: \"cat1\", df1.columns[-1]: \"cat2\" }, inplace = True)\n",
    "        X = df1.drop(['cat2','cat1'], axis=1)\n",
    "        y = df1['cat2']\n",
    "        x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=20)\n",
    "        \n",
    "        clf = LinearSVC()\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred_train = clf.predict(x_train)\n",
    "        y_pred_test = clf.predict(x_test)\n",
    "        print(\"training accuracy:\", round(accuracy_score(y_train,y_pred_train),4), \"\\n\"\n",
    "         \"test accuracy:\", round(accuracy_score(y_test,y_pred_test),4))\n",
    "        print(\"F1 score:\", round(f1_score(y_test,y_pred_test,average = 'weighted'),4))\n",
    "        print(metrics.classification_report(y_test, y_pred_test, target_names=y.unique()))\n",
    "        dump(clf, model_name + '.joblib')\n",
    "        print('model has been saved in the same location as this notebook')\n",
    "    elif model_type == \"X1\":\n",
    "        cat1 = original_data['cat1'].reset_index(drop=True)\n",
    "        cat2 = original_data['cat2'].reset_index(drop=True)\n",
    "        df1 = pd.concat([encoded_data,cat1,cat2],axis=1,ignore_index=True)\n",
    "        df1.rename(columns={ df1.columns[-2]: \"cat1\", df1.columns[-1]: \"cat2\" }, inplace = True)\n",
    "        X = df1.drop(['cat2','cat1'], axis=1)\n",
    "        y = df1['cat1']\n",
    "        x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=20)\n",
    "        \n",
    "        clf = LinearSVC()\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred_train = clf.predict(x_train)\n",
    "        y_pred_test = clf.predict(x_test)\n",
    "        print(\"training accuracy:\", round(accuracy_score(y_train,y_pred_train),4), \"\\n\"\n",
    "         \"test accuracy:\", round(accuracy_score(y_test,y_pred_test),4))\n",
    "        print(\"F1 score:\", round(f1_score(y_test,y_pred_test,average = 'weighted'),4))\n",
    "        print(metrics.classification_report(y_test, y_pred_test, target_names=y.unique()))\n",
    "        dump(clf, model_name + '.joblib')\n",
    "        print('model has been saved in the same location as this notebook')\n",
    "    elif model_type == \"X2X\":\n",
    "        cat1 = original_data['cat1'].reset_index(drop=True)\n",
    "        cat2 = original_data['cat2'].reset_index(drop=True)\n",
    "        df1 = pd.concat([encoded_data,cat1,cat2],axis=1,ignore_index=True)\n",
    "        df1.rename(columns={ df1.columns[-2]: \"cat1\", df1.columns[-1]: \"cat2\" }, inplace = True)\n",
    "        u = df1['cat1'].unique()\n",
    "        for c in u:\n",
    "            df_sub = df1[df1['cat1']==c]\n",
    "            X = df_sub.drop(['cat2','cat1'], axis=1)\n",
    "            y = df_sub['cat2']\n",
    "            x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=20)\n",
    "        \n",
    "            clf = LinearSVC()\n",
    "            clf.fit(x_train,y_train)\n",
    "            y_pred_train = clf.predict(x_train)\n",
    "            y_pred_test = clf.predict(x_test)\n",
    "            print(\"training accuracy:\", round(accuracy_score(y_train,y_pred_train),4), \"\\n\"\n",
    "             \"test accuracy:\", round(accuracy_score(y_test,y_pred_test),4))\n",
    "            print(\"F1 score:\", round(f1_score(y_test,y_pred_test,average = 'weighted'),4))\n",
    "            print(metrics.classification_report(y_test, y_pred_test, target_names=y.unique()))\n",
    "            dump(clf, model_name + '('+c+')'+'.joblib')\n",
    "            print('model ' +model_name+ '('+c+')'+' has been saved in the same location as this notebook')\n",
    "        \n",
    "    else:\n",
    "        print('Valid model types are: X, X1, X2X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in Encoded set\n",
    "df = pd.read_csv('C:/Users/Junhong/Google Drive/Spring 2020/Capstone Project/Data/Final Datasets/Home_Furniture_Appliances_clean.csv')\n",
    "#y, input is the original set\n",
    "#y = pd.read_csv('C:/Users/Junhong/Google Drive/Spring 2020/Capstone Project/Data/Final Datasets/electronics_clean.csv')\n",
    "y = pd.read_csv('C:/Users/Junhong/Google Drive/Spring 2020/Capstone Project/Data/Final Datasets//beauty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9859 \n",
      "test accuracy: 0.9399\n",
      "F1 score: 0.9395\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           Desks       0.89      1.00      0.94        39\n",
      "          Chairs       1.00      0.89      0.94        47\n",
      "       TV Stands       0.90      0.84      0.87        55\n",
      "           Sofas       0.95      0.98      0.97        43\n",
      "      Mattresses       0.95      0.91      0.93        45\n",
      "            Beds       0.90      1.00      0.95        43\n",
      "       Bookcases       0.93      1.00      0.96        40\n",
      "         Vacuums       0.94      0.94      0.94        48\n",
      "      Microwaves       0.86      0.86      0.86        43\n",
      "         Fridges       0.93      0.93      0.93        42\n",
      "     Dishwashers       0.94      0.92      0.93        50\n",
      " Washer & Dryers       0.91      0.89      0.90        46\n",
      "Small Appliances       0.89      0.91      0.90        35\n",
      "  Ovens & Ranges       1.00      0.96      0.98        48\n",
      "        Wall Art       0.93      0.93      0.93        46\n",
      "         Candles       0.95      1.00      0.98        63\n",
      "            Rugs       0.97      0.98      0.98        61\n",
      "   Throw Pillows       1.00      1.00      1.00        38\n",
      "        Curtains       0.90      0.84      0.87        43\n",
      "       Lightings       1.00      1.00      1.00        45\n",
      "         Mirrors       0.83      0.92      0.87        48\n",
      "      Dinnerware       0.97      0.97      0.97        36\n",
      "        Cookware       1.00      0.96      0.98        54\n",
      "    Food Storage       0.98      0.98      0.98        47\n",
      " Tools & Gadgets       0.82      0.74      0.78        43\n",
      "         Barware       0.96      1.00      0.98        44\n",
      "         Cutlery       1.00      1.00      1.00        48\n",
      "        Flatware       1.00      0.95      0.97        41\n",
      "\n",
      "        accuracy                           0.94      1281\n",
      "       macro avg       0.94      0.94      0.94      1281\n",
      "    weighted avg       0.94      0.94      0.94      1281\n",
      "\n",
      "model has been saved in the same location as this notebook\n"
     ]
    }
   ],
   "source": [
    "model_maker(encoded_data = df, original_data=y, model_name='H', model_type='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9883 \n",
      "test accuracy: 0.9649\n",
      "F1 score: 0.9649\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Furnitures       0.97      0.98      0.97       335\n",
      "      Appliances       0.97      0.97      0.97       343\n",
      "      Home Decor       0.96      0.95      0.96       307\n",
      "Kitchen & Dining       0.95      0.96      0.96       296\n",
      "\n",
      "        accuracy                           0.96      1281\n",
      "       macro avg       0.96      0.96      0.96      1281\n",
      "    weighted avg       0.96      0.96      0.96      1281\n",
      "\n",
      "model has been saved in the same location as this notebook\n"
     ]
    }
   ],
   "source": [
    "model_maker(encoded_data = df, original_data=y, model_name='H1', model_type='X1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9935 \n",
      "test accuracy: 0.9451\n",
      "F1 score: 0.9449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Desks       0.98      0.98      0.98        46\n",
      "      Chairs       0.93      0.98      0.95        43\n",
      "   TV Stands       0.88      0.88      0.88        40\n",
      "       Sofas       0.90      0.88      0.89        40\n",
      "  Mattresses       1.00      0.98      0.99        58\n",
      "        Beds       0.94      0.90      0.92        51\n",
      "   Bookcases       0.96      1.00      0.98        50\n",
      "\n",
      "    accuracy                           0.95       328\n",
      "   macro avg       0.94      0.94      0.94       328\n",
      "weighted avg       0.95      0.95      0.94       328\n",
      "\n",
      "model H2(Furnitures) has been saved in the same location as this notebook\n",
      "training accuracy: 0.9739 \n",
      "test accuracy: 0.9543\n",
      "F1 score: 0.9542\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         Vacuums       0.98      0.98      0.98        53\n",
      "      Microwaves       0.98      0.96      0.97        51\n",
      "         Fridges       0.95      0.95      0.95        38\n",
      "     Dishwashers       0.86      0.86      0.86        43\n",
      " Washer & Dryers       0.93      0.91      0.92        46\n",
      "Small Appliances       1.00      1.00      1.00        44\n",
      "  Ovens & Ranges       0.96      1.00      0.98        53\n",
      "\n",
      "        accuracy                           0.95       328\n",
      "       macro avg       0.95      0.95      0.95       328\n",
      "    weighted avg       0.95      0.95      0.95       328\n",
      "\n",
      "model H2(Appliances) has been saved in the same location as this notebook\n",
      "training accuracy: 1.0 \n",
      "test accuracy: 0.9936\n",
      "F1 score: 0.9936\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Wall Art       1.00      0.97      0.98        32\n",
      "      Candles       1.00      1.00      1.00        40\n",
      "         Rugs       0.98      0.98      0.98        42\n",
      "Throw Pillows       0.98      1.00      0.99        48\n",
      "     Curtains       1.00      1.00      1.00        49\n",
      "    Lightings       1.00      1.00      1.00        59\n",
      "      Mirrors       1.00      1.00      1.00        44\n",
      "\n",
      "     accuracy                           0.99       314\n",
      "    macro avg       0.99      0.99      0.99       314\n",
      " weighted avg       0.99      0.99      0.99       314\n",
      "\n",
      "model H2(Home Decor) has been saved in the same location as this notebook\n",
      "training accuracy: 0.9876 \n",
      "test accuracy: 0.9423\n",
      "F1 score: 0.9421\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     Dinnerware       1.00      0.95      0.98        44\n",
      "       Cookware       0.94      0.94      0.94        35\n",
      "   Food Storage       0.95      0.95      0.95        40\n",
      "Tools & Gadgets       0.96      0.96      0.96        45\n",
      "        Barware       0.93      0.86      0.89        43\n",
      "        Cutlery       0.94      1.00      0.97        46\n",
      "       Flatware       0.90      0.93      0.92        59\n",
      "\n",
      "       accuracy                           0.94       312\n",
      "      macro avg       0.94      0.94      0.94       312\n",
      "   weighted avg       0.94      0.94      0.94       312\n",
      "\n",
      "model H2(Kitchen & Dining) has been saved in the same location as this notebook\n"
     ]
    }
   ],
   "source": [
    "model_maker(encoded_data = df, original_data=y, model_name='H2', model_type='X2X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
